{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5d17ba6-0ad4-4959-8f1e-c01f0b5fdd07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>admittime</th>\n",
       "      <th>dischtime</th>\n",
       "      <th>gender</th>\n",
       "      <th>anchor_age</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>admission_location</th>\n",
       "      <th>discharge_location</th>\n",
       "      <th>race</th>\n",
       "      <th>...</th>\n",
       "      <th>resp_rate</th>\n",
       "      <th>o2sat</th>\n",
       "      <th>BP_systolic</th>\n",
       "      <th>BP_diastolic</th>\n",
       "      <th>other_uti</th>\n",
       "      <th>other_uti_present</th>\n",
       "      <th>has_cauti_history</th>\n",
       "      <th>pain_documented</th>\n",
       "      <th>ventilator_used</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>2180-05-06 22:23:00</td>\n",
       "      <td>2180-05-07 17:15:00</td>\n",
       "      <td>F</td>\n",
       "      <td>52</td>\n",
       "      <td>URGENT</td>\n",
       "      <td>TRANSFER FROM HOSPITAL</td>\n",
       "      <td>HOME</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000032</td>\n",
       "      <td>29079034</td>\n",
       "      <td>2180-07-23 12:35:00</td>\n",
       "      <td>2180-07-25 17:55:00</td>\n",
       "      <td>F</td>\n",
       "      <td>52</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>EMERGENCY ROOM</td>\n",
       "      <td>HOME</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000032</td>\n",
       "      <td>25742920</td>\n",
       "      <td>2180-08-05 23:44:00</td>\n",
       "      <td>2180-08-07 17:50:00</td>\n",
       "      <td>F</td>\n",
       "      <td>52</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>EMERGENCY ROOM</td>\n",
       "      <td>HOSPICE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000560</td>\n",
       "      <td>28979390</td>\n",
       "      <td>2189-10-15 10:30:00</td>\n",
       "      <td>2189-10-17 15:00:00</td>\n",
       "      <td>F</td>\n",
       "      <td>53</td>\n",
       "      <td>SURGICAL SAME DAY ADMISSION</td>\n",
       "      <td>PHYSICIAN REFERRAL</td>\n",
       "      <td>HOME</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000690</td>\n",
       "      <td>25860671</td>\n",
       "      <td>2150-11-02 18:02:00</td>\n",
       "      <td>2150-11-12 13:45:00</td>\n",
       "      <td>F</td>\n",
       "      <td>86</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>EMERGENCY ROOM</td>\n",
       "      <td>REHAB</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id            admittime            dischtime gender  \\\n",
       "0    10000032  22595853  2180-05-06 22:23:00  2180-05-07 17:15:00      F   \n",
       "1    10000032  29079034  2180-07-23 12:35:00  2180-07-25 17:55:00      F   \n",
       "2    10000032  25742920  2180-08-05 23:44:00  2180-08-07 17:50:00      F   \n",
       "3    10000560  28979390  2189-10-15 10:30:00  2189-10-17 15:00:00      F   \n",
       "4    10000690  25860671  2150-11-02 18:02:00  2150-11-12 13:45:00      F   \n",
       "\n",
       "   anchor_age               admission_type      admission_location  \\\n",
       "0          52                       URGENT  TRANSFER FROM HOSPITAL   \n",
       "1          52                     EW EMER.          EMERGENCY ROOM   \n",
       "2          52                     EW EMER.          EMERGENCY ROOM   \n",
       "3          53  SURGICAL SAME DAY ADMISSION      PHYSICIAN REFERRAL   \n",
       "4          86                     EW EMER.          EMERGENCY ROOM   \n",
       "\n",
       "  discharge_location   race  ...  resp_rate o2sat BP_systolic  BP_diastolic  \\\n",
       "0               HOME  WHITE  ...       16.0  98.0       110.0          65.0   \n",
       "1               HOME  WHITE  ...       24.0  92.0        98.0          66.0   \n",
       "2            HOSPICE  WHITE  ...       18.0  99.0        98.0          66.0   \n",
       "3               HOME  WHITE  ...        NaN   NaN       104.0          68.0   \n",
       "4              REHAB  WHITE  ...       35.0  83.0       130.0          68.0   \n",
       "\n",
       "   other_uti  other_uti_present  has_cauti_history  pain_documented  \\\n",
       "0         []              False              False             True   \n",
       "1         []              False              False             True   \n",
       "2         []              False              False             True   \n",
       "3         []              False              False             True   \n",
       "4         []              False              False            False   \n",
       "\n",
       "   ventilator_used  y  \n",
       "0            False  0  \n",
       "1             True  0  \n",
       "2             True  0  \n",
       "3            False  0  \n",
       "4            False  0  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Get project root (go up from scripts/bronze_to_silver to project root)\n",
    "PROJECT_ROOT = Path(__file__).parent.parent.parent if '__file__' in globals() else Path.cwd().parent.parent\n",
    "file_path = PROJECT_ROOT / \"data\" / \"silver\" / \"bronze_outliers_handled.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c7064e9-8187-4717-9d8c-5af4698453aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing summary saved to: C:\\Users\\Coditas\\Desktop\\Projects\\Cauti\\data\\silver\\missing_summary.csv\n"
     ]
    }
   ],
   "source": [
    "missing_summary = pd.DataFrame({\n",
    "    \"missing_count\": df.isna().sum(),\n",
    "    \"missing_percent\": (df.isna().mean() * 100).round(2)\n",
    "}).sort_values(\"missing_percent\", ascending=False)\n",
    "\n",
    "# Add non-missing count\n",
    "missing_summary[\"non_missing_count\"] = len(df) - missing_summary[\"missing_count\"]\n",
    "\n",
    "# Create combined column in the format \"Missing - num1; Non-Missing - num2\"\n",
    "missing_summary[\"missing_non_missing\"] = (\n",
    "    \"Missing - \" + missing_summary[\"missing_count\"].astype(str) + \n",
    "    \"; Non-Missing - \" + missing_summary[\"non_missing_count\"].astype(str)\n",
    ")\n",
    "\n",
    "missing_summary\n",
    "\n",
    "# Save missing summary to CSV\n",
    "output_path = PROJECT_ROOT / \"data\" / \"silver\" / \"missing_summary.csv\"\n",
    "missing_summary.to_csv(output_path, index=True)\n",
    "print(f\"Missing summary saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22a03562-a50f-4fa3-9be3-12813a0c874b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['discharge_location', 'final_insertion_date', 'final_removal_date', 'catheter_duration_days', 'BMI', 'catheter_size', 'urinalysis_wbc', 'urinalysis_rbc', 'urinalysis_nitrite', 'urine_bacteria', 'blood_wbc', 'creatinine', 'blood_crp', 'urine_output_ml', 'cfu_count', 'temperature', 'heart_rate', 'resp_rate', 'o2sat', 'BP_systolic', 'BP_diastolic']\n"
     ]
    }
   ],
   "source": [
    "missing_only = df.loc[:, df.isna().any()]\n",
    "print(missing_only.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9f2730a-ccc2-498b-9870-11e79ca90b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        missing_count  missing_percentage\n",
      "urine_bacteria                 157797               99.86\n",
      "catheter_duration_days         156447               99.00\n",
      "final_removal_date             156260               98.89\n",
      "blood_crp                      147072               93.07\n",
      "cfu_count                      145635               92.16\n",
      "urine_output_ml                137052               86.73\n",
      "final_insertion_date           130051               82.30\n",
      "urinalysis_wbc                 110558               69.96\n",
      "urinalysis_rbc                 109895               69.54\n",
      "catheter_size                  105328               66.65\n",
      "urinalysis_nitrite              89116               56.40\n",
      "BP_diastolic                    55647               35.22\n",
      "BP_systolic                     55651               35.22\n",
      "temperature                     47963               30.35\n",
      "o2sat                           47659               30.16\n",
      "resp_rate                       47067               29.79\n",
      "heart_rate                      47020               29.76\n",
      "BMI                             46374               29.35\n",
      "discharge_location              15245                9.65\n",
      "creatinine                      10339                6.54\n",
      "blood_wbc                        9953                6.30\n"
     ]
    }
   ],
   "source": [
    "missing_only = pd.DataFrame({\n",
    "    \"missing_count\": df.isna().sum(),\n",
    "    \"missing_percentage\": (df.isna().mean() * 100).round(2)\n",
    "})\n",
    "\n",
    "# Keep only columns that actually have missing values\n",
    "missing_only = missing_only[missing_only[\"missing_count\"] > 0]\n",
    "\n",
    "# Sort by highest missing percentage\n",
    "missing_only = missing_only.sort_values(\"missing_percentage\", ascending=False)\n",
    "\n",
    "print(missing_only)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988b036b-b8c7-463e-9c35-6ea8c0346536",
   "metadata": {},
   "source": [
    "## BMI Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10a563ca-f753-46a6-9f40-09271ef9c8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BMI Null Count: 44298\n",
      "Total Rows: 158020\n",
      "Percentage Null: 28.03 %\n",
      "BMI Null Count: 0\n",
      "Total Rows: 158020\n",
      "Percentage Null: 0.0 %\n"
     ]
    }
   ],
   "source": [
    "# Sort by target + patient + admission time\n",
    "df = df.sort_values([\"y\", \"subject_id\", \"admittime\"])\n",
    "\n",
    "# --------------------------------------------------\n",
    "#  Forward fill BMI within (y, subject_id)\n",
    "# --------------------------------------------------\n",
    "df[\"BMI\"] = df.groupby([\"y\", \"subject_id\"])[\"BMI\"].ffill()\n",
    "\n",
    "# --------------------------------------------------\n",
    "#  Backward fill BMI within (y, subject_id)\n",
    "# --------------------------------------------------\n",
    "df[\"BMI\"] = df.groupby([\"y\", \"subject_id\"])[\"BMI\"].bfill()\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Missing summary (after ffill/bfill)\n",
    "# --------------------------------------------------\n",
    "null_count = df[\"BMI\"].isna().sum()\n",
    "total = len(df)\n",
    "percent_null = round((null_count / total) * 100, 2)\n",
    "\n",
    "print(\"BMI Null Count:\", null_count)\n",
    "print(\"Total Rows:\", total)\n",
    "print(\"Percentage Null:\", percent_null, \"%\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "#  Create age bins (same as before)\n",
    "# --------------------------------------------------\n",
    "bins = [0, 30, 45, 60, 75, 120]\n",
    "labels = [\"<30\", \"30-45\", \"45-60\", \"60-75\", \"75+\"]\n",
    "\n",
    "df[\"age_group\"] = pd.cut(df[\"anchor_age\"], bins=bins, labels=labels, right=False)\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "#  Compute median BMI per (y, age_group, gender)\n",
    "# --------------------------------------------------\n",
    "group_medians = (\n",
    "    df.groupby([\"y\", \"age_group\", \"gender\"], observed=False)[\"BMI\"]\n",
    "      .median()\n",
    ")\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "#  Fill remaining nulls using class-specific medians\n",
    "# --------------------------------------------------\n",
    "def fill_bmi(row):\n",
    "    if pd.isna(row[\"BMI\"]):\n",
    "        return group_medians.loc[row[\"y\"], row[\"age_group\"], row[\"gender\"]]\n",
    "    return row[\"BMI\"]\n",
    "\n",
    "df[\"BMI\"] = df.apply(fill_bmi, axis=1)\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "#  Cleanup\n",
    "# --------------------------------------------------\n",
    "df.drop(columns=[\"age_group\"], inplace=True)\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Final missing summary\n",
    "# --------------------------------------------------\n",
    "null_count = df[\"BMI\"].isna().sum()\n",
    "total = len(df)\n",
    "percent_null = round((null_count / total) * 100, 2)\n",
    "\n",
    "print(\"BMI Null Count:\", null_count)\n",
    "print(\"Total Rows:\", total)\n",
    "print(\"Percentage Null:\", percent_null, \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe74c876-36ae-420a-ba29-a1211b6c7adc",
   "metadata": {},
   "source": [
    "## urinalysis_wbc Missing values handling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cf17714-6c1d-482a-a26b-91fd0bad489b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urinalysis_wbc Null Count: 0\n",
      "Total Rows: 158020\n",
      "Percentage Null: 0.0 %\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# make sure age_group exists\n",
    "df[\"age_group\"] = pd.cut(\n",
    "    df[\"anchor_age\"],\n",
    "    bins=[0, 18, 40, 65, 120],\n",
    "    labels=[\"child\", \"adult\", \"middle_age\", \"elderly\"]\n",
    ")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 1️⃣ group median by (y, age_group, gender)\n",
    "# --------------------------------------------------\n",
    "group_median = (\n",
    "    df.groupby([\"y\", \"age_group\", \"gender\"], observed=False)[\"urinalysis_wbc\"]\n",
    "      .median()\n",
    ")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2️⃣ join group_median back onto df\n",
    "# --------------------------------------------------\n",
    "df = df.join(\n",
    "    group_median.rename(\"urinalysis_wbc_group_median\"),\n",
    "    on=[\"y\", \"age_group\", \"gender\"]\n",
    ")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3️⃣ fallback overall median *within each y*\n",
    "# --------------------------------------------------\n",
    "overall_median_by_y = df.groupby(\"y\")[\"urinalysis_wbc\"].median()\n",
    "\n",
    "df[\"urinalysis_wbc_group_median\"] = df.apply(\n",
    "    lambda row: (\n",
    "        overall_median_by_y.loc[row[\"y\"]]\n",
    "        if pd.isna(row[\"urinalysis_wbc_group_median\"])\n",
    "        else row[\"urinalysis_wbc_group_median\"]\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 4️⃣ fill missing urinalysis_wbc\n",
    "# --------------------------------------------------\n",
    "df[\"urinalysis_wbc\"] = df[\"urinalysis_wbc\"].fillna(\n",
    "    df[\"urinalysis_wbc_group_median\"]\n",
    ")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 5️⃣ cleanup\n",
    "# --------------------------------------------------\n",
    "df = df.drop(columns=[\"urinalysis_wbc_group_median\"])\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Missing summary\n",
    "# --------------------------------------------------\n",
    "null_count = df[\"urinalysis_wbc\"].isna().sum()\n",
    "total = len(df)\n",
    "percent_null = round((null_count / total) * 100, 2)\n",
    "\n",
    "print(\"urinalysis_wbc Null Count:\", null_count)\n",
    "print(\"Total Rows:\", total)\n",
    "print(\"Percentage Null:\", percent_null, \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c0ae1e-5c0e-4bfa-9e79-8d8e64608d7d",
   "metadata": {},
   "source": [
    "## urinalysis_rbc Missing values handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1aeebc59-4242-4c7e-a60a-37c733489210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urinalysis_rbc Null Count: 0\n",
      "Total Rows: 158020\n",
      "Percentage Null: 0.0 %\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ensure age_group exists (safe to repeat)\n",
    "df[\"age_group\"] = pd.cut(\n",
    "    df[\"anchor_age\"],\n",
    "    bins=[0, 18, 40, 65, 120],\n",
    "    labels=[\"child\", \"adult\", \"middle_age\", \"elderly\"]\n",
    ")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Group median by (y, age_group, gender)\n",
    "# --------------------------------------------------\n",
    "group_median_rbc = (\n",
    "    df.groupby([\"y\", \"age_group\", \"gender\"], observed=False)[\"urinalysis_rbc\"]\n",
    "      .median()\n",
    ")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Join onto df\n",
    "# --------------------------------------------------\n",
    "df = df.join(\n",
    "    group_median_rbc.rename(\"urinalysis_rbc_group_median\"),\n",
    "    on=[\"y\", \"age_group\", \"gender\"]\n",
    ")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Fallback median within each y\n",
    "# --------------------------------------------------\n",
    "overall_median_rbc_by_y = df.groupby(\"y\")[\"urinalysis_rbc\"].median()\n",
    "\n",
    "df[\"urinalysis_rbc_group_median\"] = df.apply(\n",
    "    lambda row: (\n",
    "        overall_median_rbc_by_y.loc[row[\"y\"]]\n",
    "        if pd.isna(row[\"urinalysis_rbc_group_median\"])\n",
    "        else row[\"urinalysis_rbc_group_median\"]\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# --------------------------------------------------\n",
    "#  Fill missing values\n",
    "# --------------------------------------------------\n",
    "df[\"urinalysis_rbc\"] = df[\"urinalysis_rbc\"].fillna(\n",
    "    df[\"urinalysis_rbc_group_median\"]\n",
    ")\n",
    "\n",
    "# --------------------------------------------------\n",
    "#  Cleanup\n",
    "# --------------------------------------------------\n",
    "df = df.drop(columns=[\"urinalysis_rbc_group_median\"])\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Missing summary\n",
    "# --------------------------------------------------\n",
    "null_count = df[\"urinalysis_rbc\"].isna().sum()\n",
    "total = len(df)\n",
    "percent_null = round((null_count / total) * 100, 2)\n",
    "\n",
    "print(\"urinalysis_rbc Null Count:\", null_count)\n",
    "print(\"Total Rows:\", total)\n",
    "print(\"Percentage Null:\", percent_null, \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e144010-a6a7-48fe-85d5-f2b7c80152d5",
   "metadata": {},
   "source": [
    "## blood_wbc Missing values handling\n",
    "\n",
    "**NOTE: This section is now handled by advanced K-NN imputation in `3b_b2s_advanced_imputation_knn_mice.ipynb`**\n",
    "\n",
    "The code below is commented out. Use the advanced imputation notebook for better relationship-aware imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13c2812f-4a43-4cc8-a785-e9ab2fa507dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blood_wbc imputation: Using advanced K-NN imputation (see 3b_b2s_advanced_imputation_knn_mice.ipynb)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# COMMENTED OUT: Now handled by advanced K-NN imputation\n",
    "# See: scripts/bronze_to_silver/3b_b2s_advanced_imputation_knn_mice.ipynb\n",
    "# ============================================================================\n",
    "\n",
    "# # Ensure age_group exists\n",
    "# df[\"age_group\"] = pd.cut(\n",
    "#     df[\"anchor_age\"],\n",
    "#     bins=[0, 18, 40, 65, 120],\n",
    "#     labels=[\"child\", \"adult\", \"middle_age\", \"elderly\"]\n",
    "# )\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# #  Group median by (y, age_group, gender)\n",
    "# # --------------------------------------------------\n",
    "# group_median_blood_wbc = (\n",
    "#     df.groupby([\"y\", \"age_group\", \"gender\"], observed=False)[\"blood_wbc\"]\n",
    "#       .median()\n",
    "# )\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# #  Join group median onto df\n",
    "# # --------------------------------------------------\n",
    "# df = df.join(\n",
    "#     group_median_blood_wbc.rename(\"blood_wbc_group_median\"),\n",
    "#     on=[\"y\", \"age_group\", \"gender\"]\n",
    "# )\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# #  Fallback median within each y\n",
    "# # --------------------------------------------------\n",
    "# overall_median_blood_wbc_by_y = df.groupby(\"y\")[\"blood_wbc\"].median()\n",
    "\n",
    "# df[\"blood_wbc_group_median\"] = df.apply(\n",
    "#     lambda row: (\n",
    "#         overall_median_blood_wbc_by_y.loc[row[\"y\"]]\n",
    "#         if pd.isna(row[\"blood_wbc_group_median\"])\n",
    "#         else row[\"blood_wbc_group_median\"]\n",
    "#     ),\n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# #  Fill NA\n",
    "# # --------------------------------------------------\n",
    "# df[\"blood_wbc\"] = df[\"blood_wbc\"].fillna(\n",
    "#     df[\"blood_wbc_group_median\"]\n",
    "# )\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# #  Drop helper column\n",
    "# # --------------------------------------------------\n",
    "# df = df.drop(columns=[\"blood_wbc_group_median\"])\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # Missing summary\n",
    "# # --------------------------------------------------\n",
    "# null_count = df[\"blood_wbc\"].isna().sum()\n",
    "# total = len(df)\n",
    "# percent_null = round((null_count / total) * 100, 2)\n",
    "\n",
    "# print(\"blood_wbc Null Count:\", null_count)\n",
    "# print(\"Total Rows:\", total)\n",
    "# print(\"Percentage Null:\", percent_null, \"%\")\n",
    "\n",
    "print(\"blood_wbc imputation: Using advanced K-NN imputation (see 3b_b2s_advanced_imputation_knn_mice.ipynb)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062a4249-3947-4ea4-9f5e-17e8b805d469",
   "metadata": {},
   "source": [
    "## creatinine Missing Values handling\n",
    "\n",
    "**NOTE: This section is now handled by advanced K-NN imputation in `3b_b2s_advanced_imputation_knn_mice.ipynb`**\n",
    "\n",
    "The code below is commented out. Use the advanced imputation notebook for better relationship-aware imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c887d06-d887-4b59-8de1-07e6435eebd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creatinine imputation: Using advanced K-NN imputation (see 3b_b2s_advanced_imputation_knn_mice.ipynb)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# COMMENTED OUT: Now handled by advanced K-NN imputation\n",
    "# See: scripts/bronze_to_silver/3b_b2s_advanced_imputation_knn_mice.ipynb\n",
    "# ============================================================================\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # 0) Ensure numeric\n",
    "# df[\"creatinine\"] = pd.to_numeric(df[\"creatinine\"], errors=\"coerce\")\n",
    "\n",
    "# # 1) Make age_group if not already present\n",
    "# if \"age_group\" not in df.columns:\n",
    "#     df[\"age_group\"] = pd.cut(\n",
    "#         df[\"anchor_age\"],\n",
    "#         bins=[0, 18, 40, 65, 120],\n",
    "#         labels=[\"child\", \"adult\", \"middle_age\", \"elderly\"]\n",
    "#     )\n",
    "\n",
    "# # 2) Sort so ffill/bfill within patient makes sense (class-aware)\n",
    "# df = df.sort_values([\"y\", \"subject_id\", \"admittime\"])\n",
    "\n",
    "# # 3) Patient-wise forward then backward fill within (y, subject_id)\n",
    "# df[\"creatinine\"] = df.groupby([\"y\", \"subject_id\"])[\"creatinine\"].ffill()\n",
    "# df[\"creatinine\"] = df.groupby([\"y\", \"subject_id\"])[\"creatinine\"].bfill()\n",
    "\n",
    "# # 4) Compute group median by (y, age_group, gender)\n",
    "# group_med = (\n",
    "#     df.groupby([\"y\", \"age_group\", \"gender\"], observed=False)[\"creatinine\"]\n",
    "#       .median()\n",
    "# )\n",
    "\n",
    "# # 5) Join group median back on df\n",
    "# df = df.join(\n",
    "#     group_med.rename(\"creatinine_group_median\"),\n",
    "#     on=[\"y\", \"age_group\", \"gender\"]\n",
    "# )\n",
    "\n",
    "# # 6) Fallback overall median within each y\n",
    "# overall_med_by_y = df.groupby(\"y\")[\"creatinine\"].median()\n",
    "\n",
    "# df[\"creatinine_group_median\"] = df.apply(\n",
    "#     lambda row: (\n",
    "#         overall_med_by_y.loc[row[\"y\"]]\n",
    "#         if pd.isna(row[\"creatinine_group_median\"])\n",
    "#         else row[\"creatinine_group_median\"]\n",
    "#     ),\n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# # 7) Fill remaining missing creatinine\n",
    "# df[\"creatinine\"] = df[\"creatinine\"].fillna(\n",
    "#     df[\"creatinine_group_median\"]\n",
    "# )\n",
    "\n",
    "# # 8) Drop helper column\n",
    "# df = df.drop(columns=[\"creatinine_group_median\"])\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # Missing summary\n",
    "# # --------------------------------------------------\n",
    "# null_count = df[\"creatinine\"].isna().sum()\n",
    "# total = len(df)\n",
    "# percent_null = round((null_count / total) * 100, 2)\n",
    "\n",
    "# print(\"creatinine Null Count:\", null_count)\n",
    "# print(\"Total Rows:\", total)\n",
    "# print(\"Percentage Null:\", percent_null, \"%\")\n",
    "\n",
    "print(\"creatinine imputation: Using advanced K-NN imputation (see 3b_b2s_advanced_imputation_knn_mice.ipynb)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bc5139-7042-487e-8e97-c48a536b70bf",
   "metadata": {},
   "source": [
    "## Temperature Missing values Handling\n",
    "\n",
    "**NOTE: This section is now handled by advanced K-NN imputation in `3b_b2s_advanced_imputation_knn_mice.ipynb`**\n",
    "\n",
    "The code below is commented out. Use the advanced imputation notebook for better relationship-aware imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d9cc36a-ee4f-45e5-9f7d-06ea39e4cc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temperature imputation: Using advanced K-NN imputation (see 3b_b2s_advanced_imputation_knn_mice.ipynb)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# COMMENTED OUT: Now handled by advanced K-NN imputation\n",
    "# See: scripts/bronze_to_silver/3b_b2s_advanced_imputation_knn_mice.ipynb\n",
    "# ============================================================================\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # Sort by class, patient and time\n",
    "# # --------------------------------------------------\n",
    "# df = df.sort_values([\"y\", \"subject_id\", \"admittime\"])\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# #  Forward fill within (y, subject_id)\n",
    "# # --------------------------------------------------\n",
    "# df[\"temperature\"] = df.groupby([\"y\", \"subject_id\"])[\"temperature\"].ffill()\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# #  Backward fill within (y, subject_id)\n",
    "# # --------------------------------------------------\n",
    "# df[\"temperature\"] = df.groupby([\"y\", \"subject_id\"])[\"temperature\"].bfill()\n",
    "\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # Missing summary after temporal fill\n",
    "# # --------------------------------------------------\n",
    "# null_count = df[\"temperature\"].isna().sum()\n",
    "# total = len(df)\n",
    "# percent_null = round((null_count / total) * 100, 2)\n",
    "\n",
    "# print(\"temperature Null Count:\", null_count)\n",
    "# print(\"Total Rows:\", total)\n",
    "# print(\"Percentage Null:\", percent_null, \"%\")\n",
    "\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# #  Group median by (y, age_group, gender)\n",
    "# # --------------------------------------------------\n",
    "# group_median = (\n",
    "#     df.groupby([\"y\", \"age_group\", \"gender\"], observed=False)[\"temperature\"]\n",
    "#       .median()\n",
    "# )\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # Join group median onto df\n",
    "# # --------------------------------------------------\n",
    "# df = df.join(\n",
    "#     group_median.rename(\"temperature_group_median\"),\n",
    "#     on=[\"y\", \"age_group\", \"gender\"]\n",
    "# )\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # Fallback median within each y\n",
    "# # --------------------------------------------------\n",
    "# overall_median_by_y = df.groupby(\"y\")[\"temperature\"].median()\n",
    "\n",
    "# df[\"temperature_group_median\"] = df.apply(\n",
    "#     lambda row: (\n",
    "#         overall_median_by_y.loc[row[\"y\"]]\n",
    "#         if pd.isna(row[\"temperature_group_median\"])\n",
    "#         else row[\"temperature_group_median\"]\n",
    "#     ),\n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# #  Fill remaining missing temperature values\n",
    "# # --------------------------------------------------\n",
    "# df[\"temperature\"] = df[\"temperature\"].fillna(\n",
    "#     df[\"temperature_group_median\"]\n",
    "# )\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # Drop helper column\n",
    "# # --------------------------------------------------\n",
    "# df = df.drop(columns=[\"temperature_group_median\"])\n",
    "\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # Final missing summary\n",
    "# # --------------------------------------------------\n",
    "# null_count = df[\"temperature\"].isna().sum()\n",
    "# total = len(df)\n",
    "# percent_null = round((null_count / total) * 100, 2)\n",
    "\n",
    "# print(\"temperature Null Count:\", null_count)\n",
    "# print(\"Total Rows:\", total)\n",
    "# print(\"Percentage Null:\", percent_null, \"%\")\n",
    "\n",
    "print(\"temperature imputation: Using advanced K-NN imputation (see 3b_b2s_advanced_imputation_knn_mice.ipynb)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220d093b-c17b-4bd4-bd6f-674aec7ad4e2",
   "metadata": {},
   "source": [
    "## heart_rate missing values\n",
    "\n",
    "**NOTE: This section is now handled by advanced K-NN imputation in `3b_b2s_advanced_imputation_knn_mice.ipynb`**\n",
    "\n",
    "The code below is commented out. Use the advanced imputation notebook for better relationship-aware imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6c81cbf-0701-4e67-81fd-c1e3d2207c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heart_rate imputation: Using advanced K-NN imputation (see 3b_b2s_advanced_imputation_knn_mice.ipynb)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# COMMENTED OUT: Now handled by advanced K-NN imputation\n",
    "# See: scripts/bronze_to_silver/3b_b2s_advanced_imputation_knn_mice.ipynb\n",
    "# ============================================================================\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # Safety: ensure admittime datetime\n",
    "# # --------------------------------------------------\n",
    "# df[\"admittime\"] = pd.to_datetime(df[\"admittime\"], errors=\"coerce\")\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # 1️⃣ Sort by class, patient, and time\n",
    "# # --------------------------------------------------\n",
    "# df = df.sort_values([\"y\", \"subject_id\", \"admittime\"])\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # 2️⃣ Patient-wise forward then backward fill within (y, subject_id)\n",
    "# # --------------------------------------------------\n",
    "# df[\"heart_rate\"] = df.groupby([\"y\", \"subject_id\"])[\"heart_rate\"].ffill()\n",
    "# df[\"heart_rate\"] = df.groupby([\"y\", \"subject_id\"])[\"heart_rate\"].bfill()\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # Missing summary after temporal fill\n",
    "# # --------------------------------------------------\n",
    "# null_count = df[\"heart_rate\"].isna().sum()\n",
    "# total = len(df)\n",
    "# percent_null = round((null_count / total) * 100, 2)\n",
    "\n",
    "# print(\"heart_rate Null Count:\", null_count)\n",
    "# print(\"Total Rows:\", total)\n",
    "# print(\"Percentage Null:\", percent_null, \"%\")\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # 3️⃣ Ensure age_group exists\n",
    "# # --------------------------------------------------\n",
    "# if \"age_group\" not in df.columns:\n",
    "#     df[\"age_group\"] = pd.cut(\n",
    "#         df[\"anchor_age\"],\n",
    "#         bins=[0, 18, 40, 65, 120],\n",
    "#         labels=[\"child\", \"adult\", \"middle_age\", \"elderly\"]\n",
    "#     )\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # 4️⃣ Group median by (y, age_group, gender)\n",
    "# # --------------------------------------------------\n",
    "# group_median = (\n",
    "#     df.groupby([\"y\", \"age_group\", \"gender\"], observed=False)[\"heart_rate\"]\n",
    "#       .median()\n",
    "# )\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # 5️⃣ Join group median onto df\n",
    "# # --------------------------------------------------\n",
    "# df = df.join(\n",
    "#     group_median.rename(\"hr_group_median\"),\n",
    "#     on=[\"y\", \"age_group\", \"gender\"]\n",
    "# )\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # 6️⃣ Fallback median within each y\n",
    "# # --------------------------------------------------\n",
    "# overall_median_by_y = df.groupby(\"y\")[\"heart_rate\"].median()\n",
    "\n",
    "# df[\"hr_group_median\"] = df.apply(\n",
    "#     lambda row: (\n",
    "#         overall_median_by_y.loc[row[\"y\"]]\n",
    "#         if pd.isna(row[\"hr_group_median\"])\n",
    "#         else row[\"hr_group_median\"]\n",
    "#     ),\n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # 7️⃣ Fill remaining missing heart_rate values\n",
    "# # --------------------------------------------------\n",
    "# df[\"heart_rate\"] = df[\"heart_rate\"].fillna(df[\"hr_group_median\"])\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # 8️⃣ Drop helper column\n",
    "# # --------------------------------------------------\n",
    "# df = df.drop(columns=[\"hr_group_median\"])\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # Final missing summary\n",
    "# # --------------------------------------------------\n",
    "# null_count = df[\"heart_rate\"].isna().sum()\n",
    "# total = len(df)\n",
    "# percent_null = round((null_count / total) * 100, 2)\n",
    "\n",
    "# print(\"heart_rate Null Count:\", null_count)\n",
    "# print(\"Total Rows:\", total)\n",
    "# print(\"Percentage Null:\", percent_null, \"%\")\n",
    "\n",
    "print(\"heart_rate imputation: Using advanced K-NN imputation (see 3b_b2s_advanced_imputation_knn_mice.ipynb)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2406c514-2ab1-489d-811d-1420f15ebcbe",
   "metadata": {},
   "source": [
    "## resp_rate missing values handling\n",
    "\n",
    "**NOTE: This section is now handled by advanced K-NN imputation in `3b_b2s_advanced_imputation_knn_mice.ipynb`**\n",
    "\n",
    "The code below is commented out. Use the advanced imputation notebook for better relationship-aware imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6085c35c-b190-4c65-a482-10ed8c07a940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp_rate imputation: Using advanced K-NN imputation (see 3b_b2s_advanced_imputation_knn_mice.ipynb)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# COMMENTED OUT: Now handled by advanced K-NN imputation\n",
    "# See: scripts/bronze_to_silver/3b_b2s_advanced_imputation_knn_mice.ipynb\n",
    "# ============================================================================\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # Safety: ensure admittime datetime\n",
    "# # --------------------------------------------------\n",
    "# df[\"admittime\"] = pd.to_datetime(df[\"admittime\"], errors=\"coerce\")\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # Sort by class, patient, and time\n",
    "# # --------------------------------------------------\n",
    "# df = df.sort_values([\"y\", \"subject_id\", \"admittime\"])\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # Patient-wise forward then backward fill within (y, subject_id)\n",
    "# # --------------------------------------------------\n",
    "# df[\"resp_rate\"] = df.groupby([\"y\", \"subject_id\"])[\"resp_rate\"].ffill()\n",
    "# df[\"resp_rate\"] = df.groupby([\"y\", \"subject_id\"])[\"resp_rate\"].bfill()\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # Missing summary after temporal fill\n",
    "# # --------------------------------------------------\n",
    "# null_count = df[\"resp_rate\"].isna().sum()\n",
    "# total = len(df)\n",
    "# percent_null = round((null_count / total) * 100, 2)\n",
    "\n",
    "# print(\"resp_rate Null Count:\", null_count)\n",
    "# print(\"Total Rows:\", total)\n",
    "# print(\"Percentage Null:\", percent_null, \"%\")\n",
    "\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # Ensure age_group exists\n",
    "# # --------------------------------------------------\n",
    "# if \"age_group\" not in df.columns:\n",
    "#     df[\"age_group\"] = pd.cut(\n",
    "#         df[\"anchor_age\"],\n",
    "#         bins=[0, 18, 40, 65, 120],\n",
    "#         labels=[\"child\", \"adult\", \"middle_age\", \"elderly\"]\n",
    "#     )\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # Group median by (y, age_group, gender)\n",
    "# # --------------------------------------------------\n",
    "# group_median = (\n",
    "#     df.groupby([\"y\", \"age_group\", \"gender\"], observed=False)[\"resp_rate\"]\n",
    "#       .median()\n",
    "# )\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # Join group median onto df\n",
    "# # --------------------------------------------------\n",
    "# df = df.join(\n",
    "#     group_median.rename(\"rr_group_median\"),\n",
    "#     on=[\"y\", \"age_group\", \"gender\"]\n",
    "# )\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# #  Fallback median within each y\n",
    "# # --------------------------------------------------\n",
    "# overall_median_by_y = df.groupby(\"y\")[\"resp_rate\"].median()\n",
    "\n",
    "# df[\"rr_group_median\"] = df.apply(\n",
    "#     lambda row: (\n",
    "#         overall_median_by_y.loc[row[\"y\"]]\n",
    "#         if pd.isna(row[\"rr_group_median\"])\n",
    "#         else row[\"rr_group_median\"]\n",
    "#     ),\n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# #  Fill remaining NaNs\n",
    "# # --------------------------------------------------\n",
    "# df[\"resp_rate\"] = df[\"resp_rate\"].fillna(df[\"rr_group_median\"])\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# #  Drop helper column\n",
    "# # --------------------------------------------------\n",
    "# df = df.drop(columns=[\"rr_group_median\"])\n",
    "\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # Final missing summary\n",
    "# # --------------------------------------------------\n",
    "# null_count = df[\"resp_rate\"].isna().sum()\n",
    "# total = len(df)\n",
    "# percent_null = round((null_count / total) * 100, 2)\n",
    "\n",
    "# print(\"resp_rate Null Count:\", null_count)\n",
    "# print(\"Total Rows:\", total)\n",
    "# print(\"Percentage Null:\", percent_null, \"%\")\n",
    "\n",
    "print(\"resp_rate imputation: Using advanced K-NN imputation (see 3b_b2s_advanced_imputation_knn_mice.ipynb)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339acc8d-6b68-45a5-9823-8eeb7577eed7",
   "metadata": {},
   "source": [
    "## o2sat Missing Values Handling\n",
    "\n",
    "**NOTE: This section is now handled by advanced K-NN imputation in `3b_b2s_advanced_imputation_knn_mice.ipynb`**\n",
    "\n",
    "The code below is commented out. Use the advanced imputation notebook for better relationship-aware imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71ff6292-9246-4ad4-93d4-d09445131d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o2sat imputation: Using advanced K-NN imputation (see 3b_b2s_advanced_imputation_knn_mice.ipynb)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# COMMENTED OUT: Now handled by advanced K-NN imputation\n",
    "# See: scripts/bronze_to_silver/3b_b2s_advanced_imputation_knn_mice.ipynb\n",
    "# ============================================================================\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # ensure admittime is datetime\n",
    "# # --------------------------------------------------\n",
    "# df[\"admittime\"] = pd.to_datetime(df[\"admittime\"], errors=\"coerce\")\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # patient-wise time-ordered ffill then bfill\n",
    "# #     (class-aware)\n",
    "# # --------------------------------------------------\n",
    "# df = df.sort_values([\"y\", \"subject_id\", \"admittime\"])\n",
    "# df[\"o2sat\"] = df.groupby([\"y\", \"subject_id\"])[\"o2sat\"].ffill()\n",
    "# df[\"o2sat\"] = df.groupby([\"y\", \"subject_id\"])[\"o2sat\"].bfill()\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # Missing summary after temporal fill\n",
    "# # --------------------------------------------------\n",
    "# null_count = df[\"o2sat\"].isna().sum()\n",
    "# total = len(df)\n",
    "# percent_null = round((null_count / total) * 100, 2)\n",
    "\n",
    "# print(\"o2sat Null Count:\", null_count)\n",
    "# print(\"Total Rows:\", total)\n",
    "# print(\"Percentage Null:\", percent_null, \"%\")\n",
    "\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# #  ensure age_group exists\n",
    "# # --------------------------------------------------\n",
    "# if \"age_group\" not in df.columns:\n",
    "#     df[\"age_group\"] = pd.cut(\n",
    "#         df[\"anchor_age\"],\n",
    "#         bins=[0, 18, 40, 65, 120],\n",
    "#         labels=[\"child\", \"adult\", \"middle_age\", \"elderly\"]\n",
    "#     )\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# #  group median by (y, age_group, icu_admission)\n",
    "# # --------------------------------------------------\n",
    "# group_median = (\n",
    "#     df.groupby(\n",
    "#         [\"y\", \"age_group\", \"icu_admission\"],\n",
    "#         observed=False\n",
    "#     )[\"o2sat\"]\n",
    "#     .median()\n",
    "# )\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# #  join group median back onto df\n",
    "# # --------------------------------------------------\n",
    "# df = df.drop(columns=[\"o2_group_median\"], errors=\"ignore\")\n",
    "# df = df.join(\n",
    "#     group_median.rename(\"o2_group_median\"),\n",
    "#     on=[\"y\", \"age_group\", \"icu_admission\"]\n",
    "# )\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# #  fallback median within each y\n",
    "# # --------------------------------------------------\n",
    "# overall_median_by_y = df.groupby(\"y\")[\"o2sat\"].median()\n",
    "\n",
    "# df[\"o2_group_median\"] = df.apply(\n",
    "#     lambda row: (\n",
    "#         overall_median_by_y.loc[row[\"y\"]]\n",
    "#         if pd.isna(row[\"o2_group_median\"])\n",
    "#         else row[\"o2_group_median\"]\n",
    "#     ),\n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# #  fill remaining missing values\n",
    "# # --------------------------------------------------\n",
    "# df[\"o2sat_filled\"] = df[\"o2sat\"].fillna(df[\"o2_group_median\"])\n",
    "\n",
    "# df[\"o2sat_filled\"] = df[\"o2sat_filled\"].fillna(\n",
    "#     df[\"y\"].map(overall_median_by_y)\n",
    "# )\n",
    "# # --------------------------------------------------\n",
    "# #  final numeric coercion\n",
    "# # --------------------------------------------------\n",
    "# df[\"o2sat_final\"] = pd.to_numeric(df[\"o2sat_filled\"], errors=\"coerce\")\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# #  overwrite original column\n",
    "# # --------------------------------------------------\n",
    "# df[\"o2sat\"] = df[\"o2sat_final\"]\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# #  cleanup helper columns\n",
    "# # --------------------------------------------------\n",
    "# df = df.drop(\n",
    "#     columns=[\"o2_group_median\", \"o2sat_filled\", \"o2sat_final\"],\n",
    "#     errors=\"ignore\"\n",
    "# )\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # Final missing summary\n",
    "# # --------------------------------------------------\n",
    "# null_count = df[\"o2sat\"].isna().sum()\n",
    "# total = len(df)\n",
    "# percent_null = round((null_count / total) * 100, 2)\n",
    "\n",
    "# print(\"o2sat Null Count:\", null_count)\n",
    "# print(\"Total Rows:\", total)\n",
    "# print(\"Percentage Null:\", percent_null, \"%\")\n",
    "\n",
    "print(\"o2sat imputation: Using advanced K-NN imputation (see 3b_b2s_advanced_imputation_knn_mice.ipynb)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993988a3-1d98-40a5-9747-a9560472ec44",
   "metadata": {},
   "source": [
    "## BP_systolic Missing Values Handling\n",
    "\n",
    "**NOTE: This section is now handled by advanced MICE imputation in `3b_b2s_advanced_imputation_knn_mice.ipynb`**\n",
    "\n",
    "The code below is commented out. Use the advanced imputation notebook for better relationship-aware imputation (models correlation between BP_systolic and BP_diastolic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38e2b216-69d9-4646-b520-bf038ac0e91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BP_systolic and BP_diastolic imputation: Using advanced MICE imputation (see 3b_b2s_advanced_imputation_knn_mice.ipynb)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# COMMENTED OUT: Now handled by advanced MICE imputation\n",
    "# See: scripts/bronze_to_silver/3b_b2s_advanced_imputation_knn_mice.ipynb\n",
    "# MICE models the correlation between BP_systolic and BP_diastolic\n",
    "# ============================================================================\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # Sort by class, patient, and time\n",
    "# # --------------------------------------------------\n",
    "# df = df.sort_values([\"y\", \"subject_id\", \"admittime\"])\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # Patient-wise forward & backward fill within (y, subject_id)\n",
    "# # --------------------------------------------------\n",
    "# df[\"BP_systolic\"] = (\n",
    "#     df.groupby([\"y\", \"subject_id\"])[\"BP_systolic\"]\n",
    "#       .ffill()\n",
    "#       .bfill()\n",
    "# )\n",
    "\n",
    "# df[\"BP_diastolic\"] = (\n",
    "#     df.groupby([\"y\", \"subject_id\"])[\"BP_diastolic\"]\n",
    "#       .ffill()\n",
    "#       .bfill()\n",
    "# )\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # Missing summary after temporal fill\n",
    "# # --------------------------------------------------\n",
    "# for col in [\"BP_systolic\", \"BP_diastolic\"]:\n",
    "#     null_count = df[col].isna().sum()\n",
    "#     total = len(df)\n",
    "#     percent_null = round((null_count / total) * 100, 2)\n",
    "#     print(f\"{col} Null Count:\", null_count)\n",
    "#     print(\"Total Rows:\", total)\n",
    "#     print(\"Percentage Null:\", percent_null, \"%\")\n",
    "#     print()\n",
    "\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # Ensure age_group exists\n",
    "# # --------------------------------------------------\n",
    "# df[\"age_group\"] = pd.cut(\n",
    "#     df[\"anchor_age\"],\n",
    "#     bins=[0, 18, 40, 65, 120],\n",
    "#     labels=[\"child\", \"adult\", \"middle_age\", \"elderly\"]\n",
    "# )\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # Compute group medians by (y, age_group, icu_admission)\n",
    "# # --------------------------------------------------\n",
    "# bp_sys_group = (\n",
    "#     df.groupby(\n",
    "#         [\"y\", \"age_group\", \"icu_admission\"],\n",
    "#         observed=False\n",
    "#     )[\"BP_systolic\"]\n",
    "#     .median()\n",
    "# )\n",
    "\n",
    "# bp_dias_group = (\n",
    "#     df.groupby(\n",
    "#         [\"y\", \"age_group\", \"icu_admission\"],\n",
    "#         observed=False\n",
    "#     )[\"BP_diastolic\"]\n",
    "#     .median()\n",
    "# )\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # Drop old helper columns if re-running\n",
    "# # --------------------------------------------------\n",
    "# df = df.drop(\n",
    "#     columns=[\"bp_sys_group_median\", \"bp_dias_group_median\"],\n",
    "#     errors=\"ignore\"\n",
    "# )\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # Join group medians back\n",
    "# # --------------------------------------------------\n",
    "# df = df.join(\n",
    "#     bp_sys_group.rename(\"bp_sys_group_median\"),\n",
    "#     on=[\"y\", \"age_group\", \"icu_admission\"]\n",
    "# )\n",
    "\n",
    "# df = df.join(\n",
    "#     bp_dias_group.rename(\"bp_dias_group_median\"),\n",
    "#     on=[\"y\", \"age_group\", \"icu_admission\"]\n",
    "# )\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # Fallback median within each y\n",
    "# # --------------------------------------------------\n",
    "# sys_overall_by_y  = df.groupby(\"y\")[\"BP_systolic\"].median()\n",
    "# dias_overall_by_y = df.groupby(\"y\")[\"BP_diastolic\"].median()\n",
    "\n",
    "# df[\"bp_sys_group_median\"] = df.apply(\n",
    "#     lambda r: sys_overall_by_y.loc[r[\"y\"]]\n",
    "#     if pd.isna(r[\"bp_sys_group_median\"]) else r[\"bp_sys_group_median\"],\n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# df[\"bp_dias_group_median\"] = df.apply(\n",
    "#     lambda r: dias_overall_by_y.loc[r[\"y\"]]\n",
    "#     if pd.isna(r[\"bp_dias_group_median\"]) else r[\"bp_dias_group_median\"],\n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # Fill remaining missing values\n",
    "# # --------------------------------------------------\n",
    "# df[\"BP_systolic\"]  = df[\"BP_systolic\"].fillna(df[\"bp_sys_group_median\"])\n",
    "# df[\"BP_diastolic\"] = df[\"BP_diastolic\"].fillna(df[\"bp_dias_group_median\"])\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # Cleanup helper columns\n",
    "# # --------------------------------------------------\n",
    "# df = df.drop(columns=[\"bp_sys_group_median\", \"bp_dias_group_median\"])\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # Final missing summary\n",
    "# # --------------------------------------------------\n",
    "# for col in [\"BP_systolic\", \"BP_diastolic\"]:\n",
    "#     null_count = df[col].isna().sum()\n",
    "#     total = len(df)\n",
    "#     percent_null = round((null_count / total) * 100, 2)\n",
    "#     print(f\"{col} Null Count:\", null_count)\n",
    "#     print(\"Total Rows:\", total)\n",
    "#     print(\"Percentage Null:\", percent_null, \"%\")\n",
    "#     print()\n",
    "\n",
    "print(\"BP_systolic and BP_diastolic imputation: Using advanced MICE imputation (see 3b_b2s_advanced_imputation_knn_mice.ipynb)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4b1ca3d-a063-43dc-9d9b-784f3e11b055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        missing_count  missing_percentage\n",
      "urine_bacteria                 157797               99.86\n",
      "catheter_duration_days         156447               99.00\n",
      "final_removal_date             156260               98.89\n",
      "blood_crp                      147072               93.07\n",
      "cfu_count                      145635               92.16\n",
      "urine_output_ml                137052               86.73\n",
      "final_insertion_date           130051               82.30\n",
      "catheter_size                  105328               66.65\n",
      "urinalysis_nitrite              89116               56.40\n",
      "BP_systolic                     55651               35.22\n",
      "BP_diastolic                    55647               35.22\n",
      "temperature                     47963               30.35\n",
      "o2sat                           47659               30.16\n",
      "resp_rate                       47067               29.79\n",
      "heart_rate                      47020               29.76\n",
      "discharge_location              15245                9.65\n",
      "creatinine                      10339                6.54\n",
      "blood_wbc                        9953                6.30\n"
     ]
    }
   ],
   "source": [
    "missing_only = pd.DataFrame({\n",
    "    \"missing_count\": df.isna().sum(),\n",
    "    \"missing_percentage\": (df.isna().mean() * 100).round(2)\n",
    "})\n",
    "\n",
    "# Keep only columns that actually have missing values\n",
    "missing_only = missing_only[missing_only[\"missing_count\"] > 0]\n",
    "\n",
    "# Sort by highest missing percentage\n",
    "missing_only = missing_only.sort_values(\"missing_percentage\", ascending=False)\n",
    "\n",
    "print(missing_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed43b4b8-a5da-45fe-bb34-55bfe0fd8690",
   "metadata": {},
   "source": [
    "## discharge_location missing values handling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2a8c89e-d6df-4315-94a5-4f94012d8a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mode per class y\n",
    "mode_by_y = (\n",
    "    df.groupby(\"y\")[\"discharge_location\"]\n",
    "      .agg(lambda x: x.mode(dropna=True).iloc[0] if not x.mode(dropna=True).empty else np.nan)\n",
    ")\n",
    "\n",
    "# Fill missing values using class-specific mode\n",
    "df[\"discharge_location\"] = df[\"discharge_location\"].fillna(\n",
    "    df[\"y\"].map(mode_by_y)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0781495-05c9-46c6-9db0-a33b5d5d0c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"discharge_location\"].isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc94cdf-2f85-44a9-b35d-935fb3a9c46a",
   "metadata": {},
   "source": [
    "## urinalysis_nitrite handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7be789b0-88df-4251-8cb9-0212f13715dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#  Flag: was nitrite test performed?\n",
    "df[\"nitrite_tested\"] = df[\"urinalysis_nitrite\"].notna().astype(int)\n",
    "\n",
    "# Flag: nitrite positive (only 1 if tested and positive)\n",
    "df[\"nitrite_positive\"] = (df[\"urinalysis_nitrite\"] == 1).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "805c92da-5729-47d8-bbef-cbac44290965",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"urinalysis_nitrite\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7377fbb2-e7b4-4ae0-ac1b-53559676e983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nitrite_tested      0\n",
       "nitrite_positive    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"nitrite_tested\", \"nitrite_positive\"]].isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a748b12f-d807-4658-a062-4801462e4ff1",
   "metadata": {},
   "source": [
    "## Drop insertion and removal columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e3d96ff-689e-4cb4-b259-bcfd1e4c7403",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\n",
    "    columns=[\"final_removal_date\", \"final_insertion_date\",\"urine_bacteria\"],\n",
    "    errors=\"ignore\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad7624b1-fefa-4743-9255-1e1941833855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        missing_count  missing_percentage\n",
      "catheter_duration_days         156447               99.00\n",
      "blood_crp                      147072               93.07\n",
      "cfu_count                      145635               92.16\n",
      "urine_output_ml                137052               86.73\n",
      "catheter_size                  105328               66.65\n",
      "BP_systolic                     55651               35.22\n",
      "BP_diastolic                    55647               35.22\n",
      "temperature                     47963               30.35\n",
      "o2sat                           47659               30.16\n",
      "resp_rate                       47067               29.79\n",
      "heart_rate                      47020               29.76\n",
      "creatinine                      10339                6.54\n",
      "blood_wbc                        9953                6.30\n"
     ]
    }
   ],
   "source": [
    "missing_only = pd.DataFrame({\n",
    "    \"missing_count\": df.isna().sum(),\n",
    "    \"missing_percentage\": (df.isna().mean() * 100).round(2)\n",
    "})\n",
    "\n",
    "# Keep only columns that actually have missing values\n",
    "missing_only = missing_only[missing_only[\"missing_count\"] > 0]\n",
    "\n",
    "# Sort by highest missing percentage\n",
    "missing_only = missing_only.sort_values(\"missing_percentage\", ascending=False)\n",
    "\n",
    "print(missing_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199e1e74-5b87-4d91-8a32-f1a7779c06d0",
   "metadata": {},
   "source": [
    "## create blood_crp_measured and cfu_count_measured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f4c3f328-9027-4ae2-a187-8c6fb8de54f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blood_crp_measured\n",
      "0    147072\n",
      "1     10948\n",
      "Name: count, dtype: int64\n",
      "cfu_count_measured\n",
      "0    145635\n",
      "1     12385\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Flag: was CRP measured?\n",
    "df[\"blood_crp_measured\"] = df[\"blood_crp\"].notna().astype(int)\n",
    "\n",
    "# Flag: was urine culture (CFU) measured?\n",
    "df[\"cfu_count_measured\"] = df[\"cfu_count\"].notna().astype(int)\n",
    "print(df[\"blood_crp_measured\"].value_counts())\n",
    "print(df[\"cfu_count_measured\"].value_counts())\n",
    "df = df.drop(columns=[\"blood_crp\", \"cfu_count\"], errors=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68250afa-dc65-4906-96f0-48c79669ad2b",
   "metadata": {},
   "source": [
    "## urine_output_ml handle missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "97d8beae-a65a-4772-84c3-b609800d59af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create measured flag\n",
    "df[\"urine_output_measured\"] = df[\"urine_output_ml\"].notna().astype(int)\n",
    "\n",
    "# Drop the raw column\n",
    "df = df.drop(columns=[\"urine_output_ml\"], errors=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28b07dc3-43ec-4636-b947-a440c5ae8696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          missing_count  non_missing_count  missing_percentage\n",
      "y                                                                             \n",
      "0 catheter_duration_days         154627               1558               99.00\n",
      "  catheter_size                  104018              52167               66.60\n",
      "1 catheter_duration_days           1820                 15               99.18\n",
      "  catheter_size                    1310                525               71.39\n"
     ]
    }
   ],
   "source": [
    "cols = [\n",
    "    \"catheter_duration_days\",\n",
    "    \"catheter_size\"\n",
    "]\n",
    "\n",
    "summary_by_y = (\n",
    "    df\n",
    "    .groupby(\"y\")[cols]\n",
    "    .apply(lambda x: pd.DataFrame({\n",
    "        \"missing_count\": x.isna().sum(),\n",
    "        \"non_missing_count\": x.notna().sum(),\n",
    "        \"missing_percentage\": (x.isna().mean() * 100).round(2)\n",
    "    }))\n",
    ")\n",
    "\n",
    "print(summary_by_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c3280f-51c9-4303-b113-a0d5b1c631e8",
   "metadata": {},
   "source": [
    "## catheter_duration_days handle missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c103bb99-7380-4402-a53a-599ea563aaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"catheter_duration_measured\"] = df[\"catheter_duration_days\"].notna().astype(int)\n",
    "df = df.drop(columns=[\"catheter_duration_days\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c5b01b9a-7aa8-45c5-a26f-8957735d47e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "catheter_duration_measured\n",
       "0    156447\n",
       "1      1573\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"catheter_duration_measured\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a325e0-3747-4486-ad9b-a2e71c8ba8fb",
   "metadata": {},
   "source": [
    "## catheter_size handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d63d8749-ab63-478b-9b89-4e9a2c9e97a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"catheter_size\"] = df[\"catheter_size\"].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dc5fa956-074d-4242-882f-70f429a6fc28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              missing_count  missing_percentage\n",
      "BP_systolic           55651               35.22\n",
      "BP_diastolic          55647               35.22\n",
      "temperature           47963               30.35\n",
      "o2sat                 47659               30.16\n",
      "resp_rate             47067               29.79\n",
      "heart_rate            47020               29.76\n",
      "creatinine            10339                6.54\n",
      "blood_wbc              9953                6.30\n"
     ]
    }
   ],
   "source": [
    "missing_only = pd.DataFrame({\n",
    "    \"missing_count\": df.isna().sum(),\n",
    "    \"missing_percentage\": (df.isna().mean() * 100).round(2)\n",
    "})\n",
    "\n",
    "# Keep only columns that actually have missing values\n",
    "missing_only = missing_only[missing_only[\"missing_count\"] > 0]\n",
    "\n",
    "# Sort by highest missing percentage\n",
    "missing_only = missing_only.sort_values(\"missing_percentage\", ascending=False)\n",
    "\n",
    "print(missing_only)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a9d0530e-8cc6-4747-9de1-37484434cdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"catheter_size_known\"] = (df[\"catheter_size\"] != \"Unknown\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "689c41aa-30ff-4353-b567-fa0a8981ce71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def extract_french_size(x):\n",
    "    if pd.isna(x) or x == \"Unknown\":\n",
    "        return np.nan\n",
    "    m = re.search(r\"(\\d+)\", str(x))\n",
    "    return float(m.group(1)) if m else np.nan\n",
    "\n",
    "df[\"catheter_size_fr\"] = df[\"catheter_size\"].apply(extract_french_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e1def472-8eb2-4be8-8e7d-ed27cd98c1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"catheter_size_fr\"] = df[\"catheter_size_fr\"].clip(lower=6, upper=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fdf1ae58-fb0a-47c7-a2db-c9a4f6383185",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"catheter_size_measured\"] = df[\"catheter_size_fr\"].notna().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e0af84dc-810d-4b4e-90ad-68f743aa5da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"catheter_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "89e827aa-e2ed-42bc-b713-8102fc323325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: C:\\Users\\Coditas\\Desktop\\Projects\\Cauti\\data\\silver\\missing_summary.csv\n"
     ]
    }
   ],
   "source": [
    "save_path = PROJECT_ROOT / \"data\" / \"silver\" / \"bronze_missing_values_handled.csv\"\n",
    "\n",
    "df.to_csv(save_path, index=False)\n",
    "\n",
    "print(\"Saved to:\", output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
