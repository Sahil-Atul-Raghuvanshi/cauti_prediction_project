{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25c0e36f-31f4-41bd-96dd-b021a92eed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Feature: steroids_per_admission\n",
    "Boolean flag indicating if steroids were given during admission\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from config_paths import *\n",
    "from utils import drop_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec2eeb82-32fe-41df-b2eb-59d0ee230f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset shape: (158020, 73)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Coditas\\AppData\\Local\\Temp\\ipykernel_3576\\343384643.py:54: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"steroids_per_admission\"] = df[\"steroids\"].fillna(False).astype(bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature 'steroids_per_admission' added.\n",
      "Value counts:\n",
      "steroids_per_admission\n",
      "False    123553\n",
      "True      34467\n",
      "Name: count, dtype: int64\n",
      "Total rows: 158020\n",
      "True count: 34467\n",
      "False count: 123553\n",
      "Sum check (True + False): 158020\n",
      "Expected total: 158020\n",
      "✓ Row count matches expected total (158020)\n",
      "Dataset shape: (158020, 74)\n"
     ]
    }
   ],
   "source": [
    "# Read dataset\n",
    "df = pd.read_csv(dataset_path)\n",
    "initial_row_count = len(df)\n",
    "print(f\"Initial dataset shape: {df.shape}\")\n",
    "\n",
    "# Check for duplicates in dataset (shouldn't happen, but verify)\n",
    "duplicates = df.duplicated(subset=[\"subject_id\", \"hadm_id\"]).sum()\n",
    "if duplicates > 0:\n",
    "    print(f\"Warning: {duplicates} duplicate (subject_id, hadm_id) pairs found in dataset\")\n",
    "\n",
    "# Load prescriptions\n",
    "prescriptions = pd.read_csv(\n",
    "    os.path.join(hosp_path, \"prescriptions.csv\"),\n",
    "    usecols=[\"subject_id\", \"hadm_id\", \"drug\"]\n",
    ")\n",
    "\n",
    "# Steroid pattern\n",
    "steroid_pattern = r\"(?:pred|cort|methason|dexam|betameth|beclometh|budeson|momet|triamcinol|fludrocort)\"\n",
    "\n",
    "def drug_flag_regex(df, pattern):\n",
    "    return df[\"drug\"].str.contains(pattern, case=False, na=False, regex=True)\n",
    "\n",
    "# Build steroids flag per admission\n",
    "steroids_flag_df = (\n",
    "    prescriptions.assign(\n",
    "        steroids=lambda x: drug_flag_regex(x, steroid_pattern)\n",
    "    )\n",
    "    .groupby([\"subject_id\", \"hadm_id\"])[\"steroids\"]\n",
    "    .max()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Merge\n",
    "# Check for duplicates in steroids_flag_df (shouldn't happen after groupby, but verify)\n",
    "duplicates_flag = steroids_flag_df.duplicated(subset=[\"subject_id\", \"hadm_id\"]).sum()\n",
    "if duplicates_flag > 0:\n",
    "    print(f\"Warning: {duplicates_flag} duplicate (subject_id, hadm_id) pairs found in steroids_flag_df\")\n",
    "    # If duplicates exist, take max (shouldn't be needed, but safety check)\n",
    "    steroids_flag_df = steroids_flag_df.groupby([\"subject_id\", \"hadm_id\"])[\"steroids\"].max().reset_index()\n",
    "\n",
    "df = df.merge(steroids_flag_df, on=[\"subject_id\", \"hadm_id\"], how=\"left\")\n",
    "\n",
    "# Verify row count is preserved (left merge should keep all rows from df)\n",
    "if len(df) != initial_row_count:\n",
    "    print(f\"ERROR: Row count changed during merge! Initial: {initial_row_count}, After merge: {len(df)}\")\n",
    "    print(f\"Difference: {len(df) - initial_row_count} rows\")\n",
    "\n",
    "# Verify no new duplicates were created\n",
    "if len(df) != len(df.drop_duplicates(subset=[\"subject_id\", \"hadm_id\"])):\n",
    "    print(f\"Warning: Merge created duplicate rows. Before: {len(df.drop_duplicates(subset=['subject_id', 'hadm_id']))}, After: {len(df)}\")\n",
    "\n",
    "# Fill missing with False and convert to bool\n",
    "# Use fillna first, then convert to bool to avoid nullable boolean issues\n",
    "df[\"steroids_per_admission\"] = df[\"steroids\"].fillna(False).astype(bool)\n",
    "\n",
    "# Drop the temporary steroids column\n",
    "df = df.drop(columns=[\"steroids\"])\n",
    "\n",
    "# Save\n",
    "df.to_csv(dataset_path, index=False)\n",
    "print(f\"\\nFeature 'steroids_per_admission' added.\")\n",
    "print(f\"Value counts:\\n{df['steroids_per_admission'].value_counts()}\")\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(f\"True count: {df['steroids_per_admission'].sum()}\")\n",
    "print(f\"False count: {(~df['steroids_per_admission']).sum()}\")\n",
    "print(f\"Sum check (True + False): {df['steroids_per_admission'].sum() + (~df['steroids_per_admission']).sum()}\")\n",
    "print(f\"Expected total: {initial_row_count}\")\n",
    "if len(df) == initial_row_count:\n",
    "    print(f\"✓ Row count matches expected total ({initial_row_count})\")\n",
    "else:\n",
    "    print(f\"⚠ Row count mismatch! Expected {initial_row_count}, got {len(df)} (difference: {len(df) - initial_row_count})\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37352ac0-021a-4f24-b378-b29508a60032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject_id', 'hadm_id', 'cauti_type', 'cauti_icd_codes',\n",
       "       'other_uti_icd_codes', 'remaining_icd_codes', 'gender', 'anchor_age',\n",
       "       'admittime', 'dischtime', 'admission_type', 'admission_location',\n",
       "       'discharge_location', 'race', 'catheter_procedures',\n",
       "       'catheter_procedures_ir', 'catheter_used_in_procedures_ir',\n",
       "       'catheter_insertion_date_ir', 'catheter_removal_date_ir',\n",
       "       'catheter_outputevents', 'catheter_used_in_output_events',\n",
       "       'datetimeevents', 'catheter_used_in_datetime_events',\n",
       "       'insertion_date_from_datetimeevents',\n",
       "       'removal_date_from_datetimeevents', 'catheter_procedure_events',\n",
       "       'catheter_used_in_procedure_events', 'catheter_size_from_chartevents',\n",
       "       'index', 'catheter_clinical_notes', 'catheter_used_in_clinical_notes',\n",
       "       'catheter_present', 'final_cauti_flag', 'final_insertion_date',\n",
       "       'final_removal_date', 'catheter_duration_days', 'BMI_in_admission',\n",
       "       'BMI_computed', 'BMI_last_year', 'BMI', 'diabetes', 'cancer',\n",
       "       'chronic_kidney_disease', 'neurogenic_bladder', 'recurrent_uti',\n",
       "       'spinal_cord_injury', 'neurological_disorder',\n",
       "       'benign_prostatic_hyperplasia', 'charlson_score', 'length_of_stay',\n",
       "       'num_transfers', 'num_of_transfers', 'surgical_admission',\n",
       "       'recent_urologic_abdominal_surgery', 'icu_admission', 'mobility_status',\n",
       "       'catheter_type', 'catheter_size_from_notes', 'catheter_size',\n",
       "       'urinary_obstruction_present', 'improper_drainage_position',\n",
       "       'n_catheter_manip_unique_types', 'catheter_insertion',\n",
       "       'catheter_removal', 'catheter_removal_replacement',\n",
       "       'no_of_invasive_devices', 'multiple_invasive_devices',\n",
       "       'catheter_indication', 'catheter_care', 'closed_system',\n",
       "       'securement_device', 'antibiotics_per_admission',\n",
       "       'recent_antibiotic_use', 'steroids_per_admission'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0326491-fe53-48ec-b86e-cb582e194df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols_to_drop = [\n",
    "#  \"steroids_per_admission\"\n",
    "# ]\n",
    "# df = drop_columns(df, cols_to_drop)\n",
    "# df.to_csv(dataset_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae186e23-5398-411a-b570-42974ab058f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
